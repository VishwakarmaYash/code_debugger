from __future__ import annotations
import os
from typing import Optional
try:
    from dotenv import load_dotenv
except Exception:  # pragma: no cover - optional dev dependency
    def load_dotenv() -> None:
        return None
from config.model_config import load_config

# Attempt a soft import of the Google Generative AI client. If it's not
# available we allow a mock mode via the `USE_MOCK_GEMINI` env var so the
# rest of the app can run during development/testing without the package.
try:
    import google.generativeai as genai
except ImportError:  # pragma: no cover - environment dependent
    genai = None

load_dotenv()

class GeminiClient:
    def __init__(self, api_key: Optional[str] = None, config_path: Optional[str] = None):
        self.app_config = load_config(config_path)
        self.model_cfg = self.app_config.model

        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not found.")

        # If the real client library is unavailable, allow a developer to
        # opt-into a lightweight mock by setting USE_MOCK_GEMINI=true. This
        # avoids hard crashes during local development/testing.
        if genai is None:
            if os.getenv("USE_MOCK_GEMINI", "false").lower() == "true":
                class _MockModel:
                    def __init__(self, name: str):
                        self.name = name

                    def generate_content(self, prompt: str, generation_config: dict):
                        class _Resp:
                            def __init__(self, text: str):
                                self.text = text
                        return _Resp(f"[mock response] echo: {prompt[:200]}")

                self.model = _MockModel(self.model_cfg.name)
            else:
                raise ImportError(
                    "google.generativeai is not installed. Install via `pip install google-generativeai` "
                    "or set USE_MOCK_GEMINI=true to run with a local mock."
                )
        else:
            # Configure client
            genai.configure(api_key=self.api_key)

            # Initialize model
            self.model = genai.GenerativeModel(self.model_cfg.name)

    def ask(self, prompt: str) -> str:
        response = self.model.generate_content(
            prompt,
            generation_config={
                "temperature": self.model_cfg.temperature,
                "top_p": self.model_cfg.top_p,
                "max_output_tokens": self.model_cfg.max_output_tokens
            }
        )

        if not response or not hasattr(response, "text"):
            return "No response generated. Please try again."
        
        return response.text